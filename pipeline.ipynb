{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "### Import Packages and API keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets torch pinecone-client langchain-community faiss-cpu sentence-transformers\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "huggingface_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "if not huggingface_api_token:\n",
    "    huggingface_api_token = getpass(\"Enter your Hugging Face Hub API token: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huishingchong/agile_llm/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "# I will be using T5 model from open source huggingface library\n",
    "model_name = \"google/flan-t5-xxl\"\n",
    "llm = HuggingFaceHub(repo_id=model_name, model_kwargs={\"temperature\":0.5, \"max_length\":1024, \"max_new_tokens\":200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template-based Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will be using Langchain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "\n",
    "template= \"\"\"\n",
    "Try to be helpful as you can in Computer Science context.\n",
    "Question: {question}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# llm_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huishingchong/agile_llm/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What does AI stand for?\n",
      "bot: Artificial Intelligence\n",
      "user: What is Software Engineering?\n",
      "bot: Software Engineering is a discipline that focuses on the development of software and the engineering practices that support it.\n",
      "user: What is Cybersecurity?\n",
      "bot: Cybersecurity is the science and practice of protecting information systems from cyber attacks.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def chat_interface(textbox, chat):\n",
    "    input_dict = {'question': textbox}\n",
    "    response = llm_chain.run(input_dict)\n",
    "\n",
    "    print(\"user:\", textbox)\n",
    "    print(\"bot:\", response)\n",
    "    return response\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a question\", container=False, scale=7),\n",
    "    title=\"Chatbot\",\n",
    "    description=\"Ask Chatbot any question\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"What does AI stand for?\", \"What is Software Engineering?\", \"What is Cybersecurity?\"],\n",
    "    cache_examples=False,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Evaluating the model without any action done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load standardized test set\n",
    "\n",
    "# ROGUE? BLUE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG from synthetic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use langchain packages to help with implementing retrieval augmentation generation\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def chat_interface(textbox, chat):\n",
    "    # docs = db.similarity_search(textbox)\n",
    "    # input_dict = {'question': textbox, 'input_documents': docs }\n",
    "    input_dict = {'question': textbox}\n",
    "    response = llm_chain.run(input_dict)\n",
    "\n",
    "    print(\"user:\", textbox)\n",
    "    print(\"bot:\", response)\n",
    "    return response\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a question\", container=False, scale=7),\n",
    "    title=\"Chatbot\",\n",
    "    description=\"Ask Chatbot any question\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"What does AI stand for?\", \"What is Software Engineering?\", \"What is Cybersecurity?\"],\n",
    "    cache_examples=False,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full adapted model (combined of all approaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge retrieved\n",
    "# Augmented Prompt\n",
    "# Fine-tuned LLM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
