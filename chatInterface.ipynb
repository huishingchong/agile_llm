{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets torch langchain-community faiss-cpu sentence-transformers\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "huggingface_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "if not huggingface_api_token:\n",
    "    huggingface_api_token = getpass(\"Enter your Hugging Face Hub API token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# Define the RAG prompt template\n",
    "rag_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Answer professionally, to the best of your ability, and where appropriate, in a Computer Science educational context.\n",
    "Use the context and be specific as you can.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(template=rag_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Load data for retrieval from CSV\n",
    "def load_csv(file):\n",
    "    loader = CSVLoader(file_path=file)\n",
    "    return loader.load()\n",
    "\n",
    "# Split Documents\n",
    "def split_documents(documents):\n",
    "    text_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    return text_split.split_documents(documents)\n",
    "\n",
    "# Create a FAISS Index\n",
    "def create_index(documents):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/gtr-t5-base\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    db = FAISS.from_documents(documents, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "# Set up the LLM model for RAG\n",
    "llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\", model_kwargs={\"temperature\": 0.5, \"max_length\": 1024, \"max_new_tokens\": 200})\n",
    "\n",
    "# Initialize the RetrievalQA chain with RAG prompt\n",
    "qa = None\n",
    "\n",
    "def initialize_qa_chain(llm, retriever):\n",
    "    global qa\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True, chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}, verbose=True)\n",
    "\n",
    "def chat_interface(textbox, file):\n",
    "    if file is not None:\n",
    "        file_extension = os.path.splitext(file.name)[1].lower()\n",
    "        if file_extension == \".csv\":\n",
    "            # Load CSV file\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            documents = loader.load()\n",
    "        elif file_extension == \".pdf\":\n",
    "            # Load PDF file\n",
    "            # loader = PyPDFLoader(file_path=file)\n",
    "            loader = PyPDFLoader(file)\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # documents = loader.load_and_split()\n",
    "        else:\n",
    "            return \"Unsupported file format.\", \"No file uploaded.\"\n",
    "\n",
    "        text_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "        d = text_split.split_documents(documents)\n",
    "        print(d)\n",
    "        modelPath = \"sentence-transformers/gtr-t5-base\" # Use a t5 sentence transformer model that maps sentences & paragraphs to a 768 dimensional dense vector space\n",
    "        model_kwargs = {'device':'cpu'}\n",
    "        encode_kwargs = {'normalize_embeddings': True} # Normalizing embeddings can help improve similarity metrics by ensuring that embeddings magnitude does not affect the similarity scores\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=modelPath,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "\n",
    "        db = FAISS.from_documents(d, embedding=embeddings)\n",
    "        retriever = db.as_retriever()\n",
    "        # Initialize QA chain\n",
    "        initialize_qa_chain(llm, retriever)\n",
    "        preview = \"File uploaded successfully.\"\n",
    "\n",
    "    else:\n",
    "        preview = \"No file uploaded. No RAG.\"\n",
    "\n",
    "    if qa is not None:\n",
    "        input_dict = {'query': textbox}\n",
    "        result = qa.invoke(input_dict)\n",
    "        text = result['result']\n",
    "        print(text)\n",
    "        answer = text.split('\\nHelpful Answer:')[1].strip()\n",
    "        return answer, preview\n",
    "    \n",
    "    # Communicate directly with the language model\n",
    "    template= \"\"\"\n",
    "    Please answer the question.\n",
    "    Answer professionally, and where appropriate, in a Computer Science educational context.\n",
    "    Question: {question}\n",
    "    Response:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "    input_dict = {'question': textbox}\n",
    "    response_dict = llm_chain.invoke(input_dict)\n",
    "    response = response_dict['text'].split(\"Response:\")[1].strip()\n",
    "    return response, preview\n",
    "\n",
    "def create_demo():\n",
    "    with gr.Blocks(title=\"RAG Chatbot Q&A\", theme=\"Soft\") as demo:\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                response = gr.Text(type=\"text\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                text_input = gr.Textbox(\n",
    "                    show_label=False,\n",
    "                    placeholder=\"Ask here\",\n",
    "                container=False)\n",
    "\n",
    "            with gr.Column():\n",
    "                submit_button = gr.Button('Send')\n",
    "\n",
    "            with gr.Column():\n",
    "                # uploaded_pdf = gr.UploadButton(\"Upload file\", file_types=[\".csv\"])\n",
    "                uploaded_file = gr.File(type=\"filepath\", file_types=[\".csv\", \".pdf\"])\n",
    "\n",
    "            with gr.Column():\n",
    "                preview = gr.Textbox(label=\"Preview\", type=\"text\")\n",
    "\n",
    "    # Launch the custom interface with the components\n",
    "    gr.Interface(\n",
    "        fn=chat_interface,\n",
    "        inputs=[text_input, uploaded_file],\n",
    "        outputs=[response, preview],\n",
    "        title=\"Chatbot\",\n",
    "        description=\"Ask Chatbot any question\",\n",
    "        theme=\"soft\",\n",
    "        examples=[\n",
    "            [\"What does AI stand for?\"],\n",
    "            [\"What is Software Engineering?\"],\n",
    "            [\"What is Cybersecurity?\"]\n",
    "        ],\n",
    "        cache_examples=False,\n",
    "    ).launch()\n",
    "\n",
    "create_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
